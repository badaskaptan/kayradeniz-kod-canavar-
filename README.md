# ğŸŒŸ LUMA SUPREME - Learning & Understanding Machine Assistant

**Version**: 2.0 Supreme  
**Architecture**: Dual-Brain AI System (Claude Production + Ollama Learning)  
**Status**: Phase 1 In Development

---

## ğŸ¯ **What is LUMA?**

LUMA is not just another AI coding assistant. It's a **self-learning, self-improving system** that:

- âœ… **Learns from every interaction** - Passive observation of Claude's actions
- âœ… **Improves continuously** - Night Orders protocol for background learning
- âœ… **Teaches you best practices** - Usta Modu (Teacher Mode)
- âœ… **Analyzes deeply** - Elysion Chamber for architecture insights
- âœ… **Works offline** - Ollama-powered local inference
- âœ… **Respects privacy** - All data stored locally

---

## ğŸ—ï¸ **System Architecture**

```
Claude MCP (Production) â†â†’ Shared Context Memory â†â†’ Ollama MCP (Learning)
        â†“                           â†“                         â†“
   Tool Execution          Observations & Patterns      Agent System
   Real-time work          SQLite Database              Background learning
```

**Read full architecture**: [LUMA_SUPREME_MASTER_PLAN.md](./LUMA_SUPREME_MASTER_PLAN.md)

---

## ğŸš€ **Quick Start**

### **Prerequisites**

```bash
# Node.js 18+
node --version

# Ollama (for local LLM)
ollama --version

# If Ollama not installed:
# Visit: https://ollama.ai/download
```

### **Ollama Performance Tips**

**For best performance:**

- âœ… **Minimize Ollama Desktop** (don't close!) - runs 20-30% faster in system tray
- âœ… **Recommended models for 8GB RAM:**
  - `llama3.2:3b` - Best balance (tool calling, 5-7 sec responses)
  - `qwen2.5:7b` - Better quality (requires 16GB+ RAM)
- âš ï¸ **Avoid heavy models** like `llama3:70b` on limited RAM

### **Installation**

```bash
# Clone the repository
git clone <repository-url>
cd luma-project

# Install dependencies
npm install

# Pull Ollama models
ollama pull llama2

# Start development
npm run dev
```

### **Configuration**

1. **Claude API Key**: Settings â†’ Claude API tab â†’ Enter your API key
2. **Ollama Setup**: Settings â†’ Ollama tab â†’ Install instructions
3. **MCP Selection**: Chat panel â†’ Toggle between Claude/Ollama

---

## ğŸ“š **Documentation**

- ğŸ“– **[Master Plan](./LUMA_SUPREME_MASTER_PLAN.md)** - Complete system architecture & roadmap
- ğŸ§ª **[Tool Test Plan](./CLAUDE_TOOL_TEST_PLAN.md)** - Testing guide for 18 Claude tools

---

## ğŸ› ï¸ **Development**

### **Available Scripts**

```bash
# Development mode (hot reload)
npm run dev

# Type checking
npm run typecheck

# Linting
npm run lint

# Format code
npm run format

# Build for production
npm run build:win    # Windows
npm run build:mac    # macOS
npm run build:linux  # Linux
```

### **Project Structure**

```
luma-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/                    # Electron main process
â”‚   â”‚   â”œâ”€â”€ claude-service.ts    # Claude MCP (18 tools)
â”‚   â”‚   â”œâ”€â”€ activity-observer.ts # Passive learning hook
â”‚   â”‚   â””â”€â”€ ipc/                 # IPC handlers
â”‚   â”œâ”€â”€ renderer/                # React UI
â”‚   â”‚   â”œâ”€â”€ components/          # UI components
â”‚   â”‚   â”œâ”€â”€ agents/              # Ollama agent system
â”‚   â”‚   â”œâ”€â”€ stores/              # Zustand state
â”‚   â”‚   â””â”€â”€ services/            # Ollama service
â”‚   â””â”€â”€ shared/                  # Shared utilities
â”‚       â””â”€â”€ shared-context-memory.ts  # SQLite learning DB
â”œâ”€â”€ LUMA_SUPREME_MASTER_PLAN.md  # ğŸ“– Read this first!
â”œâ”€â”€ CLAUDE_TOOL_TEST_PLAN.md     # Tool testing guide
â””â”€â”€ README.md                    # This file
```

---

## ğŸ¨ **Features**

### **âœ… Phase 0: Foundation (Complete)**

- Dragon Theme UI (Turquoise + Orange)
- Claude MCP with 18 tools
- Ollama MCP integration
- Dual-brain toggle system
- Settings panel (API keys, models)

### **ğŸ”„ Phase 1: Passive Learning (In Progress)**

- Activity Observer (non-blocking hooks)
- Shared Context Memory (SQLite)
- Ollama Agent System
- Pattern recognition

### **ğŸŒ™ Phase 2-6: Advanced Features (Planned)**

- Night Orders Protocol
- Usta Modu (Teacher Mode)
- Elysion Chamber (Deep analysis)
- Reflexion Engine
- Fine-tuning system

**See [Master Plan](./LUMA_SUPREME_MASTER_PLAN.md) for details.**

---

## ğŸ“ **Learning System**

LUMA learns passively by:

1. **Observing** Claude's tool executions
2. **Recording** observations to SQLite database
3. **Analyzing** patterns with Ollama agents
4. **Consolidating** knowledge during idle time (Night Orders)
5. **Teaching** best practices (Usta Modu)
6. **Improving** through reflexion

**Key Insight**: Claude never changes, Ollama learns from it!

---

## ğŸ” **Privacy & Security**

- âœ… API keys stored locally (encrypted)
- âœ… No external data transmission (except AI APIs)
- âœ… Learning database stored locally (SQLite)
- âœ… User can disable learning system
- âœ… User can clear all learned data

---

## ğŸ¤ **Contributing**

Read [LUMA_SUPREME_MASTER_PLAN.md](./LUMA_SUPREME_MASTER_PLAN.md) for architecture details.

---

## ğŸ“„ **License**

MIT

---

## ğŸ™ **Acknowledgments**

- **Anthropic** - Claude API
- **Ollama** - Local LLM infrastructure
- **Electron** - Desktop framework
- **React** - UI framework

---

**Built with ğŸ’™ by the LUMA team**  
**Last Updated**: October 25, 2025
